{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "sequence_length = 1\n",
    "input_size = 41\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 5\n",
    "batch_size = 100\n",
    "num_epochs = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# NSL-KDD datasets\n",
    "df = pd.read_csv('NSL-KDD/KDDTrain+.txt', sep=',')\n",
    "df.columns = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
    "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
    "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
    "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "       'dst_host_srv_rerror_rate', 'labels', 'difficulty']\n",
    "\n",
    "# convert categorial feature into numeric\n",
    "protocols = df.protocol_type.value_counts()\n",
    "protocols_map = {}\n",
    "for i, (prop, count) in enumerate(protocols.items()):\n",
    "    protocols_map[prop] = i\n",
    "df.protocol_type = df.protocol_type.map(protocols_map)\n",
    "\n",
    "# convert categorial feature into numeric\n",
    "services = df.service.value_counts()\n",
    "service_map = {}\n",
    "for i, (ser, count) in enumerate(services.items()):\n",
    "    service_map[ser] = i\n",
    "df.service = df.service.map(service_map)\n",
    "\n",
    "# convert categorial feature into numeric\n",
    "flag_map = {}\n",
    "flags = df.flag.value_counts()\n",
    "for i, (flag, count) in enumerate(flags.items()):\n",
    "    flag_map[flag] = i\n",
    "df.flag = df.flag.map(flag_map)\n",
    "\n",
    "# Rename every attack label: 0=normal, 1=DoS, 2=Probe, 3=R2L and 4=U2R.\n",
    "df['targets'] = df.labels.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1,\n",
    "                                   'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1,\n",
    "                                   'udpstorm': 1, 'worm': 1,'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,\n",
    "                                   'satan' : 2,'mscan' : 2,'saint' : 2,'ftp_write': 3,'guess_passwd': 3,\n",
    "                                   'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,\n",
    "                                   'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,\n",
    "                                   'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,\n",
    "                                   'sqlattack': 4,'xterm': 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125972 entries, 0 to 125971\n",
      "Data columns (total 44 columns):\n",
      "duration                       125972 non-null int64\n",
      "protocol_type                  125972 non-null int64\n",
      "service                        125972 non-null int64\n",
      "flag                           125972 non-null int64\n",
      "src_bytes                      125972 non-null int64\n",
      "dst_bytes                      125972 non-null int64\n",
      "land                           125972 non-null int64\n",
      "wrong_fragment                 125972 non-null int64\n",
      "urgent                         125972 non-null int64\n",
      "hot                            125972 non-null int64\n",
      "num_failed_logins              125972 non-null int64\n",
      "logged_in                      125972 non-null int64\n",
      "num_compromised                125972 non-null int64\n",
      "root_shell                     125972 non-null int64\n",
      "su_attempted                   125972 non-null int64\n",
      "num_root                       125972 non-null int64\n",
      "num_file_creations             125972 non-null int64\n",
      "num_shells                     125972 non-null int64\n",
      "num_access_files               125972 non-null int64\n",
      "num_outbound_cmds              125972 non-null int64\n",
      "is_host_login                  125972 non-null int64\n",
      "is_guest_login                 125972 non-null int64\n",
      "count                          125972 non-null int64\n",
      "srv_count                      125972 non-null int64\n",
      "serror_rate                    125972 non-null float64\n",
      "srv_serror_rate                125972 non-null float64\n",
      "rerror_rate                    125972 non-null float64\n",
      "srv_rerror_rate                125972 non-null float64\n",
      "same_srv_rate                  125972 non-null float64\n",
      "diff_srv_rate                  125972 non-null float64\n",
      "srv_diff_host_rate             125972 non-null float64\n",
      "dst_host_count                 125972 non-null int64\n",
      "dst_host_srv_count             125972 non-null int64\n",
      "dst_host_same_srv_rate         125972 non-null float64\n",
      "dst_host_diff_srv_rate         125972 non-null float64\n",
      "dst_host_same_src_port_rate    125972 non-null float64\n",
      "dst_host_srv_diff_host_rate    125972 non-null float64\n",
      "dst_host_serror_rate           125972 non-null float64\n",
      "dst_host_srv_serror_rate       125972 non-null float64\n",
      "dst_host_rerror_rate           125972 non-null float64\n",
      "dst_host_srv_rerror_rate       125972 non-null float64\n",
      "labels                         125972 non-null object\n",
      "difficulty                     125972 non-null int64\n",
      "targets                        125972 non-null int64\n",
      "dtypes: float64(15), int64(28), object(1)\n",
      "memory usage: 42.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Datatype of target is object, change it to int \n",
    "df['targets'] = df['targets'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate featues and target\n",
    "X = df.drop(['labels', 'difficulty', 'targets'], axis=1)\n",
    "y = df['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       " pandas.core.frame.DataFrame,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.series.Series)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(x_test), type(y_train), type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Feature Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_filter = VarianceThreshold(threshold=0)\n",
    "const_filter.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_filter.get_support().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_list = [feature for feature in const_filter.get_support()]\n",
    "constant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "       'num_access_files', 'is_guest_login', 'count', 'srv_count',\n",
       "       'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
       "       'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
       "       'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remaining features after removing constant feature\n",
    "cols_label= X.columns[constant_list]\n",
    "cols_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([0]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['num_outbound_cmds'].unique(), X_train['is_host_login'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cons_filter = const_filter.transform(X_train)\n",
    "x_test_cons_filter = const_filter.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100777, 39), (25195, 39))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test datasets after constant feature remove\n",
    "X_train_cons_filter.shape, x_test_cons_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi constant Feature Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those features which are almost constant (99 percent)\n",
    "quasi_constant_filter = VarianceThreshold(threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.01)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_constant_filter.fit(X_train_cons_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_constant_filter.get_support().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_quasi_constant_filter = quasi_constant_filter.transform(X_train_cons_filter)\n",
    "x_test__quasi_constant_filter = quasi_constant_filter.transform(x_test_cons_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100777, 31), (25195, 31))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_quasi_constant_filter.shape, x_test__quasi_constant_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_list = [feature for feature in quasi_constant_filter.get_support()]\n",
    "constant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
      "       'dst_bytes', 'wrong_fragment', 'hot', 'logged_in', 'num_compromised',\n",
      "       'num_root', 'num_file_creations', 'count', 'srv_count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate'],\n",
      "      dtype='object')\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# print remaining list of features\n",
    "print(cols_label[constant_list]), print(len(cols_label[constant_list]))\n",
    "cols_label_2 = cols_label[constant_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate Feature Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = X_train_quasi_constant_filter.T\n",
    "x_test_T = x_test__quasi_constant_filter.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = pd.DataFrame(X_train_T)\n",
    "x_test_T = pd.DataFrame(x_test_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31, 100777), (31, 25195))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_T.shape, x_test_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_T.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "21    False\n",
       "22    False\n",
       "23    False\n",
       "24    False\n",
       "25    False\n",
       "26    False\n",
       "27    False\n",
       "28    False\n",
       "29    False\n",
       "30    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_feaure = X_train_T.duplicated()\n",
    "duplicate_feaure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_keep = [not f for f in duplicate_feaure]\n",
    "feature_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique = X_train_T[feature_to_keep].T\n",
    "x_test_unique = x_test_T[feature_to_keep].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100777, 31), (25195, 31))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unique.shape, x_test_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ML model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomForest(X_train, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100777, 31), (25195, 31))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unique.shape, x_test_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing constant, quasi-constant and duplicate\n",
      "Accuracy:  0.9989283588013494\n",
      "CPU times: user 17.6 s, sys: 192 ms, total: 17.8 s\n",
      "Wall time: 4.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('After removing constant, quasi-constant and duplicate')\n",
    "run_randomForest(X_train_unique, x_test_unique, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing conastant\n",
      "Accuracy:  0.9990077396308792\n",
      "CPU times: user 18.8 s, sys: 192 ms, total: 19 s\n",
      "Wall time: 5.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('After removing conastant')\n",
    "run_randomForest(X_train_cons_filter, x_test_cons_filter, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing quasi-constat\n",
      "Accuracy:  0.9989283588013494\n",
      "CPU times: user 18.1 s, sys: 244 ms, total: 18.3 s\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('After removing quasi-constat')\n",
    "run_randomForest(X_train_quasi_constant_filter, x_test__quasi_constant_filter, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without removing any features\n",
      "Accuracy:  0.9989680492161143\n",
      "CPU times: user 18.3 s, sys: 256 ms, total: 18.5 s\n",
      "Wall time: 5.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Without removing any features')\n",
    "run_randomForest(X_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson Correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = X_train_unique.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7facca8fe4c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corrmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(data, threshold):\n",
    "    corr_col = set()\n",
    "    corrmat = data.corr()\n",
    "    for i in range(len(corrmat.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corrmat.iloc[i, j])> threshold:\n",
    "                colname = corrmat.columns[i]\n",
    "                corr_col.add(colname)\n",
    "    return corr_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10, 15, 17, 27, 28, 29, 30}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features = get_correlation(X_train_unique, 0.90)\n",
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['duration',\n",
       " 'protocol_type',\n",
       " 'service',\n",
       " 'flag',\n",
       " 'src_bytes',\n",
       " 'dst_bytes',\n",
       " 'wrong_fragment',\n",
       " 'hot',\n",
       " 'logged_in',\n",
       " 'num_compromised',\n",
       " 'num_file_creations',\n",
       " 'count',\n",
       " 'srv_count',\n",
       " 'serror_rate',\n",
       " 'rerror_rate',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'srv_diff_host_rate',\n",
       " 'dst_host_count',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncorr_labesl = []\n",
    "for i, col in enumerate(cols_label_2):\n",
    "    if i not in corr_features:\n",
    "        uncorr_labesl.append(col)\n",
    "print(len(uncorr_labesl))\n",
    "uncorr_labesl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_without_corr = X_train_unique.drop(labels = corr_features, axis = 1)\n",
    "X_test_without_corr = x_test_unique.drop(labels = corr_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100777, 24), (25195, 24))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_without_corr.shape, X_test_without_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing pearson correlation coefficient\n",
      "Accuracy:  0.9989283588013494\n",
      "CPU times: user 16.5 s, sys: 248 ms, total: 16.7 s\n",
      "Wall time: 4.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "print('After removing pearson correlation coefficient')\n",
    "run_randomForest(X_train_without_corr, X_test_without_corr, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100777, 41)\n",
      "Accuracy:  0.9989680492161143\n"
     ]
    }
   ],
   "source": [
    "# apply pearson correlation coefficient on initial datasets\n",
    "print(X_train.shape)\n",
    "corr_features = get_correlation(X_train, 0.90)\n",
    "# corr_features\n",
    "X_train_initial_corr = X_train.drop(labels = corr_features, axis = 1)\n",
    "X_test_initial_corr = x_test.drop(labels = corr_features, axis = 1)\n",
    "X_train_initial_corr.shape, X_test_initial_corr.shape\n",
    "# print()\n",
    "run_randomForest(X_train_initial_corr, X_test_initial_corr, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pearson correlation coffecient based group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{35, 36, 37, 38, 15, 23, 25}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.176394</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.039088</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>-0.009777</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050892</td>\n",
       "      <td>-0.109289</td>\n",
       "      <td>-0.115546</td>\n",
       "      <td>0.253848</td>\n",
       "      <td>0.227889</td>\n",
       "      <td>-0.026399</td>\n",
       "      <td>-0.064810</td>\n",
       "      <td>-0.063982</td>\n",
       "      <td>0.174528</td>\n",
       "      <td>0.198709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061750</td>\n",
       "      <td>-0.277219</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.006560</td>\n",
       "      <td>0.128855</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>-0.042002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074146</td>\n",
       "      <td>0.068764</td>\n",
       "      <td>0.209410</td>\n",
       "      <td>-0.021308</td>\n",
       "      <td>0.569278</td>\n",
       "      <td>0.364310</td>\n",
       "      <td>-0.278256</td>\n",
       "      <td>-0.277162</td>\n",
       "      <td>-0.136476</td>\n",
       "      <td>-0.166853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002528</td>\n",
       "      <td>-0.061750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283294</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>-0.001220</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>-0.041014</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265421</td>\n",
       "      <td>-0.464282</td>\n",
       "      <td>-0.481485</td>\n",
       "      <td>0.048423</td>\n",
       "      <td>-0.086222</td>\n",
       "      <td>-0.054611</td>\n",
       "      <td>0.404127</td>\n",
       "      <td>0.409593</td>\n",
       "      <td>0.101639</td>\n",
       "      <td>0.109540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.176394</td>\n",
       "      <td>-0.277219</td>\n",
       "      <td>0.283294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034534</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>-0.055612</td>\n",
       "      <td>-0.004819</td>\n",
       "      <td>-0.049942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227613</td>\n",
       "      <td>-0.472394</td>\n",
       "      <td>-0.508303</td>\n",
       "      <td>0.344514</td>\n",
       "      <td>-0.042851</td>\n",
       "      <td>-0.070647</td>\n",
       "      <td>0.273909</td>\n",
       "      <td>0.280337</td>\n",
       "      <td>0.601219</td>\n",
       "      <td>0.644820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054169</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.034534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004400</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>-0.005766</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>0.007065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.039088</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.001220</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>-0.004737</td>\n",
       "      <td>-0.005024</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>-0.003214</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.012611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.001622</td>\n",
       "      <td>-0.006560</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.001398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026695</td>\n",
       "      <td>-0.014891</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>-0.004493</td>\n",
       "      <td>0.034695</td>\n",
       "      <td>0.070904</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>-0.005435</td>\n",
       "      <td>-0.005554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.009777</td>\n",
       "      <td>0.128855</td>\n",
       "      <td>-0.041014</td>\n",
       "      <td>-0.055612</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040414</td>\n",
       "      <td>-0.045733</td>\n",
       "      <td>-0.049032</td>\n",
       "      <td>0.056631</td>\n",
       "      <td>0.036108</td>\n",
       "      <td>-0.016115</td>\n",
       "      <td>-0.051692</td>\n",
       "      <td>-0.055601</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>-0.033472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004586</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>-0.004819</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005726</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>-0.005887</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>-0.004818</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>-0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.042002</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>-0.049942</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>-0.001398</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>-0.051510</td>\n",
       "      <td>-0.035967</td>\n",
       "      <td>-0.010876</td>\n",
       "      <td>-0.034460</td>\n",
       "      <td>-0.024248</td>\n",
       "      <td>-0.058061</td>\n",
       "      <td>-0.057932</td>\n",
       "      <td>-0.029851</td>\n",
       "      <td>-0.031210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011804</td>\n",
       "      <td>-0.012061</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.002419</td>\n",
       "      <td>0.110689</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025739</td>\n",
       "      <td>-0.023225</td>\n",
       "      <td>-0.001835</td>\n",
       "      <td>-0.001643</td>\n",
       "      <td>-0.005353</td>\n",
       "      <td>0.005655</td>\n",
       "      <td>-0.012071</td>\n",
       "      <td>-0.012664</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.016957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.064302</td>\n",
       "      <td>-0.359285</td>\n",
       "      <td>-0.361632</td>\n",
       "      <td>-0.440542</td>\n",
       "      <td>-0.002267</td>\n",
       "      <td>-0.003332</td>\n",
       "      <td>-0.011959</td>\n",
       "      <td>-0.072075</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.115718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>0.623796</td>\n",
       "      <td>0.602679</td>\n",
       "      <td>-0.254972</td>\n",
       "      <td>-0.162210</td>\n",
       "      <td>-0.056095</td>\n",
       "      <td>-0.491137</td>\n",
       "      <td>-0.492686</td>\n",
       "      <td>-0.275336</td>\n",
       "      <td>-0.272967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.041729</td>\n",
       "      <td>-0.005224</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>0.035103</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010879</td>\n",
       "      <td>-0.010427</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>-0.002255</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>-0.004380</td>\n",
       "      <td>-0.004725</td>\n",
       "      <td>-0.003639</td>\n",
       "      <td>-0.003345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.051551</td>\n",
       "      <td>-0.016498</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>-0.002418</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>-0.003310</td>\n",
       "      <td>0.086343</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028856</td>\n",
       "      <td>-0.006773</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>-0.004578</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>-0.017768</td>\n",
       "      <td>-0.015371</td>\n",
       "      <td>-0.008906</td>\n",
       "      <td>-0.009580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.083835</td>\n",
       "      <td>-0.011092</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.002225</td>\n",
       "      <td>0.111474</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012667</td>\n",
       "      <td>-0.021692</td>\n",
       "      <td>-0.016670</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>-0.006150</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>-0.006697</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>-0.004294</td>\n",
       "      <td>-0.005431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.044548</td>\n",
       "      <td>-0.005528</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>0.034281</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011406</td>\n",
       "      <td>-0.011184</td>\n",
       "      <td>-0.006177</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>-0.001934</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>-0.004753</td>\n",
       "      <td>-0.005059</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>-0.003607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.091529</td>\n",
       "      <td>-0.011636</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>0.030251</td>\n",
       "      <td>0.022945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001672</td>\n",
       "      <td>-0.019635</td>\n",
       "      <td>-0.017488</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>-0.006350</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>-0.004675</td>\n",
       "      <td>-0.004720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.001918</td>\n",
       "      <td>-0.008422</td>\n",
       "      <td>-0.002851</td>\n",
       "      <td>-0.011846</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009394</td>\n",
       "      <td>-0.012706</td>\n",
       "      <td>-0.006478</td>\n",
       "      <td>-0.003328</td>\n",
       "      <td>0.014769</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>-0.011376</td>\n",
       "      <td>-0.010052</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.006854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.067210</td>\n",
       "      <td>-0.017944</td>\n",
       "      <td>-0.010301</td>\n",
       "      <td>-0.020019</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>-0.000597</td>\n",
       "      <td>-0.003600</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>-0.003054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>-0.012659</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>-0.017940</td>\n",
       "      <td>-0.019583</td>\n",
       "      <td>-0.012568</td>\n",
       "      <td>-0.012746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001965</td>\n",
       "      <td>-0.042844</td>\n",
       "      <td>0.025053</td>\n",
       "      <td>-0.053472</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.008595</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>0.864388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013131</td>\n",
       "      <td>-0.065675</td>\n",
       "      <td>-0.054148</td>\n",
       "      <td>-0.005913</td>\n",
       "      <td>-0.035255</td>\n",
       "      <td>-0.024220</td>\n",
       "      <td>-0.059927</td>\n",
       "      <td>-0.059841</td>\n",
       "      <td>-0.029849</td>\n",
       "      <td>-0.032491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.078755</td>\n",
       "      <td>0.073608</td>\n",
       "      <td>0.346879</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>-0.003851</td>\n",
       "      <td>-0.010267</td>\n",
       "      <td>-0.020873</td>\n",
       "      <td>-0.005603</td>\n",
       "      <td>-0.068376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467910</td>\n",
       "      <td>-0.394411</td>\n",
       "      <td>-0.472053</td>\n",
       "      <td>0.164268</td>\n",
       "      <td>-0.136143</td>\n",
       "      <td>-0.205615</td>\n",
       "      <td>0.458189</td>\n",
       "      <td>0.459821</td>\n",
       "      <td>0.177824</td>\n",
       "      <td>0.167923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.039382</td>\n",
       "      <td>0.531938</td>\n",
       "      <td>-0.055492</td>\n",
       "      <td>-0.171264</td>\n",
       "      <td>-0.003092</td>\n",
       "      <td>-0.001916</td>\n",
       "      <td>-0.005285</td>\n",
       "      <td>0.024031</td>\n",
       "      <td>-0.002846</td>\n",
       "      <td>-0.034457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150257</td>\n",
       "      <td>0.203454</td>\n",
       "      <td>0.182723</td>\n",
       "      <td>-0.106912</td>\n",
       "      <td>0.161665</td>\n",
       "      <td>-0.059236</td>\n",
       "      <td>-0.146457</td>\n",
       "      <td>-0.145625</td>\n",
       "      <td>-0.101942</td>\n",
       "      <td>-0.112881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.069656</td>\n",
       "      <td>-0.280374</td>\n",
       "      <td>0.401653</td>\n",
       "      <td>0.318248</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>-0.003323</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>-0.043258</td>\n",
       "      <td>-0.004914</td>\n",
       "      <td>-0.058604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395352</td>\n",
       "      <td>-0.558051</td>\n",
       "      <td>-0.623194</td>\n",
       "      <td>-0.018171</td>\n",
       "      <td>-0.276532</td>\n",
       "      <td>-0.172628</td>\n",
       "      <td>0.979045</td>\n",
       "      <td>0.981034</td>\n",
       "      <td>-0.231577</td>\n",
       "      <td>-0.226486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.069245</td>\n",
       "      <td>-0.280398</td>\n",
       "      <td>0.403483</td>\n",
       "      <td>0.310218</td>\n",
       "      <td>-0.002229</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>-0.056250</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.058234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393074</td>\n",
       "      <td>-0.555215</td>\n",
       "      <td>-0.619476</td>\n",
       "      <td>-0.028914</td>\n",
       "      <td>-0.275519</td>\n",
       "      <td>-0.170816</td>\n",
       "      <td>0.977497</td>\n",
       "      <td>0.986002</td>\n",
       "      <td>-0.235098</td>\n",
       "      <td>-0.232924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.200460</td>\n",
       "      <td>-0.165729</td>\n",
       "      <td>0.112197</td>\n",
       "      <td>0.667646</td>\n",
       "      <td>0.010134</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>-0.004122</td>\n",
       "      <td>-0.032861</td>\n",
       "      <td>-0.002886</td>\n",
       "      <td>-0.031998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070790</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.260014</td>\n",
       "      <td>0.377480</td>\n",
       "      <td>0.032614</td>\n",
       "      <td>0.034242</td>\n",
       "      <td>-0.225986</td>\n",
       "      <td>-0.224985</td>\n",
       "      <td>0.927218</td>\n",
       "      <td>0.964776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.199823</td>\n",
       "      <td>-0.166073</td>\n",
       "      <td>0.108321</td>\n",
       "      <td>0.668120</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.012425</td>\n",
       "      <td>-0.005528</td>\n",
       "      <td>-0.033315</td>\n",
       "      <td>-0.002887</td>\n",
       "      <td>-0.031186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073516</td>\n",
       "      <td>-0.251837</td>\n",
       "      <td>-0.258024</td>\n",
       "      <td>0.381989</td>\n",
       "      <td>0.029745</td>\n",
       "      <td>0.031230</td>\n",
       "      <td>-0.226210</td>\n",
       "      <td>-0.230309</td>\n",
       "      <td>0.918888</td>\n",
       "      <td>0.970648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.074757</td>\n",
       "      <td>0.257396</td>\n",
       "      <td>-0.482703</td>\n",
       "      <td>-0.478395</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>0.054629</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.069378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509290</td>\n",
       "      <td>0.704974</td>\n",
       "      <td>0.788334</td>\n",
       "      <td>-0.164309</td>\n",
       "      <td>0.280751</td>\n",
       "      <td>0.216147</td>\n",
       "      <td>-0.760993</td>\n",
       "      <td>-0.765407</td>\n",
       "      <td>-0.215915</td>\n",
       "      <td>-0.214932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.014747</td>\n",
       "      <td>-0.010746</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>0.206585</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>-0.026492</td>\n",
       "      <td>-0.002696</td>\n",
       "      <td>-0.017843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192422</td>\n",
       "      <td>-0.299466</td>\n",
       "      <td>-0.330184</td>\n",
       "      <td>0.493908</td>\n",
       "      <td>-0.010509</td>\n",
       "      <td>-0.086014</td>\n",
       "      <td>0.051301</td>\n",
       "      <td>0.047245</td>\n",
       "      <td>0.225405</td>\n",
       "      <td>0.277130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.039909</td>\n",
       "      <td>0.269141</td>\n",
       "      <td>-0.139204</td>\n",
       "      <td>-0.172228</td>\n",
       "      <td>-0.002782</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>0.040908</td>\n",
       "      <td>-0.026047</td>\n",
       "      <td>-0.002892</td>\n",
       "      <td>-0.026043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360080</td>\n",
       "      <td>0.152886</td>\n",
       "      <td>0.291126</td>\n",
       "      <td>-0.118603</td>\n",
       "      <td>0.249142</td>\n",
       "      <td>0.379751</td>\n",
       "      <td>-0.226277</td>\n",
       "      <td>-0.226698</td>\n",
       "      <td>-0.078592</td>\n",
       "      <td>-0.083413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.050892</td>\n",
       "      <td>-0.074146</td>\n",
       "      <td>0.265421</td>\n",
       "      <td>0.227613</td>\n",
       "      <td>-0.004400</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>-0.026695</td>\n",
       "      <td>0.040414</td>\n",
       "      <td>-0.005726</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302581</td>\n",
       "      <td>-0.517897</td>\n",
       "      <td>0.142474</td>\n",
       "      <td>-0.313460</td>\n",
       "      <td>-0.455401</td>\n",
       "      <td>0.411132</td>\n",
       "      <td>0.407421</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.069753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.109289</td>\n",
       "      <td>0.068764</td>\n",
       "      <td>-0.464282</td>\n",
       "      <td>-0.472394</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>-0.004737</td>\n",
       "      <td>-0.014891</td>\n",
       "      <td>-0.045733</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>-0.051510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896385</td>\n",
       "      <td>-0.390399</td>\n",
       "      <td>-0.068358</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.572867</td>\n",
       "      <td>-0.567730</td>\n",
       "      <td>-0.252624</td>\n",
       "      <td>-0.255114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.115546</td>\n",
       "      <td>0.209410</td>\n",
       "      <td>-0.481485</td>\n",
       "      <td>-0.508303</td>\n",
       "      <td>-0.005766</td>\n",
       "      <td>-0.005024</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>-0.049032</td>\n",
       "      <td>-0.005887</td>\n",
       "      <td>-0.035967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517897</td>\n",
       "      <td>0.896385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.418948</td>\n",
       "      <td>0.137008</td>\n",
       "      <td>0.197968</td>\n",
       "      <td>-0.639659</td>\n",
       "      <td>-0.632340</td>\n",
       "      <td>-0.259517</td>\n",
       "      <td>-0.260559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.253848</td>\n",
       "      <td>-0.021308</td>\n",
       "      <td>0.048423</td>\n",
       "      <td>0.344514</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>-0.004493</td>\n",
       "      <td>0.056631</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>-0.010876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142474</td>\n",
       "      <td>-0.390399</td>\n",
       "      <td>-0.418948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.232357</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>-0.017730</td>\n",
       "      <td>-0.026522</td>\n",
       "      <td>0.410382</td>\n",
       "      <td>0.386967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.227889</td>\n",
       "      <td>0.569278</td>\n",
       "      <td>-0.086222</td>\n",
       "      <td>-0.042851</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>0.034695</td>\n",
       "      <td>0.036108</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.034460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313460</td>\n",
       "      <td>-0.068358</td>\n",
       "      <td>0.137008</td>\n",
       "      <td>0.232357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404123</td>\n",
       "      <td>-0.279398</td>\n",
       "      <td>-0.277056</td>\n",
       "      <td>0.037307</td>\n",
       "      <td>0.028106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.026399</td>\n",
       "      <td>0.364310</td>\n",
       "      <td>-0.054611</td>\n",
       "      <td>-0.070647</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>0.070904</td>\n",
       "      <td>-0.016115</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>-0.024248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455401</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>0.197968</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>0.404123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.174468</td>\n",
       "      <td>-0.173138</td>\n",
       "      <td>0.039741</td>\n",
       "      <td>0.040182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.064810</td>\n",
       "      <td>-0.278256</td>\n",
       "      <td>0.404127</td>\n",
       "      <td>0.273909</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>-0.051692</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>-0.058061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411132</td>\n",
       "      <td>-0.572867</td>\n",
       "      <td>-0.639659</td>\n",
       "      <td>-0.017730</td>\n",
       "      <td>-0.279398</td>\n",
       "      <td>-0.174468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985073</td>\n",
       "      <td>-0.235077</td>\n",
       "      <td>-0.227578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.063982</td>\n",
       "      <td>-0.277162</td>\n",
       "      <td>0.409593</td>\n",
       "      <td>0.280337</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>-0.003214</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>-0.055601</td>\n",
       "      <td>-0.004818</td>\n",
       "      <td>-0.057932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407421</td>\n",
       "      <td>-0.567730</td>\n",
       "      <td>-0.632340</td>\n",
       "      <td>-0.026522</td>\n",
       "      <td>-0.277056</td>\n",
       "      <td>-0.173138</td>\n",
       "      <td>0.985073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.234381</td>\n",
       "      <td>-0.232396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.174528</td>\n",
       "      <td>-0.136476</td>\n",
       "      <td>0.101639</td>\n",
       "      <td>0.601219</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>-0.005435</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>-0.029851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>-0.252624</td>\n",
       "      <td>-0.259517</td>\n",
       "      <td>0.410382</td>\n",
       "      <td>0.037307</td>\n",
       "      <td>0.039741</td>\n",
       "      <td>-0.235077</td>\n",
       "      <td>-0.234381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.198709</td>\n",
       "      <td>-0.166853</td>\n",
       "      <td>0.109540</td>\n",
       "      <td>0.644820</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>-0.005554</td>\n",
       "      <td>-0.033472</td>\n",
       "      <td>-0.002900</td>\n",
       "      <td>-0.031210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069753</td>\n",
       "      <td>-0.255114</td>\n",
       "      <td>-0.260559</td>\n",
       "      <td>0.386967</td>\n",
       "      <td>0.028106</td>\n",
       "      <td>0.040182</td>\n",
       "      <td>-0.227578</td>\n",
       "      <td>-0.232396</td>\n",
       "      <td>0.925828</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000 -0.009967  0.002528  0.176394  0.054169  0.039088 -0.001622   \n",
       "1  -0.009967  1.000000 -0.061750 -0.277219 -0.003849 -0.002367 -0.006560   \n",
       "2   0.002528 -0.061750  1.000000  0.283294  0.004864 -0.001220  0.002541   \n",
       "3   0.176394 -0.277219  0.283294  1.000000  0.034534  0.011191  0.005891   \n",
       "4   0.054169 -0.003849  0.004864  0.034534  1.000000  0.000001 -0.000129   \n",
       "5   0.039088 -0.002367 -0.001220  0.011191  0.000001  1.000000 -0.000079   \n",
       "6  -0.001622 -0.006560  0.002541  0.005891 -0.000129 -0.000079  1.000000   \n",
       "7  -0.009777  0.128855 -0.041014 -0.055612 -0.000774 -0.000475 -0.001316   \n",
       "8   0.004586 -0.003425  0.004272 -0.004819 -0.000065  0.000256 -0.000114   \n",
       "9  -0.000132 -0.042002  0.016806 -0.049942  0.001265 -0.000396 -0.001398   \n",
       "10  0.011804 -0.012061  0.003321  0.027464 -0.000234  0.000548 -0.000401   \n",
       "11 -0.064302 -0.359285 -0.361632 -0.440542 -0.002267 -0.003332 -0.011959   \n",
       "12  0.041729 -0.005224  0.000896 -0.001048 -0.000094  0.001201 -0.000174   \n",
       "13  0.051551 -0.016498 -0.004602 -0.002418 -0.000315  0.001058 -0.000549   \n",
       "14  0.083835 -0.011092  0.002204  0.012605 -0.000211  0.001125 -0.000369   \n",
       "15  0.044548 -0.005528  0.000967 -0.001246 -0.000104  0.001197 -0.000184   \n",
       "16  0.091529 -0.011636  0.001550 -0.007319 -0.000187  0.000045 -0.000387   \n",
       "17 -0.001918 -0.008422 -0.002851 -0.011846 -0.000145 -0.000097 -0.000280   \n",
       "18  0.067210 -0.017944 -0.010301 -0.020019 -0.000336  0.000281 -0.000597   \n",
       "19  0.001965 -0.042844  0.025053 -0.053472 -0.000815 -0.000463 -0.001426   \n",
       "20 -0.078755  0.073608  0.346879  0.292977 -0.005266 -0.003851 -0.010267   \n",
       "21 -0.039382  0.531938 -0.055492 -0.171264 -0.003092 -0.001916 -0.005285   \n",
       "22 -0.069656 -0.280374  0.401653  0.318248 -0.001709 -0.003323  0.022687   \n",
       "23 -0.069245 -0.280398  0.403483  0.310218 -0.002229 -0.003299  0.023734   \n",
       "24  0.200460 -0.165729  0.112197  0.667646  0.010134  0.012564 -0.004122   \n",
       "25  0.199823 -0.166073  0.108321  0.668120  0.010809  0.012425 -0.005528   \n",
       "26  0.074757  0.257396 -0.482703 -0.478395  0.002061  0.004110  0.008852   \n",
       "27 -0.014747 -0.010746  0.089260  0.206585  0.001921 -0.001849 -0.001126   \n",
       "28 -0.039909  0.269141 -0.139204 -0.172228 -0.002782 -0.001845  0.040908   \n",
       "29  0.050892 -0.074146  0.265421  0.227613 -0.004400  0.002934 -0.026695   \n",
       "30 -0.109289  0.068764 -0.464282 -0.472394 -0.006752 -0.004737 -0.014891   \n",
       "31 -0.115546  0.209410 -0.481485 -0.508303 -0.005766 -0.005024  0.011660   \n",
       "32  0.253848 -0.021308  0.048423  0.344514  0.000672  0.012385 -0.004493   \n",
       "33  0.227889  0.569278 -0.086222 -0.042851  0.002045  0.013042  0.034695   \n",
       "34 -0.026399  0.364310 -0.054611 -0.070647 -0.001513 -0.001409  0.070904   \n",
       "35 -0.064810 -0.278256  0.404127  0.273909 -0.004560 -0.003300  0.020422   \n",
       "36 -0.063982 -0.277162  0.409593  0.280337 -0.002192 -0.003214  0.013013   \n",
       "37  0.174528 -0.136476  0.101639  0.601219 -0.001919  0.013181 -0.005435   \n",
       "38  0.198709 -0.166853  0.109540  0.644820  0.007065  0.012611 -0.005554   \n",
       "\n",
       "          7         8         9   ...        29        30        31        32  \\\n",
       "0  -0.009777  0.004586 -0.000132  ...  0.050892 -0.109289 -0.115546  0.253848   \n",
       "1   0.128855 -0.003425 -0.042002  ... -0.074146  0.068764  0.209410 -0.021308   \n",
       "2  -0.041014  0.004272  0.016806  ...  0.265421 -0.464282 -0.481485  0.048423   \n",
       "3  -0.055612 -0.004819 -0.049942  ...  0.227613 -0.472394 -0.508303  0.344514   \n",
       "4  -0.000774 -0.000065  0.001265  ... -0.004400 -0.006752 -0.005766  0.000672   \n",
       "5  -0.000475  0.000256 -0.000396  ...  0.002934 -0.004737 -0.005024  0.012385   \n",
       "6  -0.001316 -0.000114 -0.001398  ... -0.026695 -0.014891  0.011660 -0.004493   \n",
       "7   1.000000 -0.000687 -0.008426  ...  0.040414 -0.045733 -0.049032  0.056631   \n",
       "8  -0.000687  1.000000  0.000484  ... -0.005726 -0.007911 -0.005887  0.005119   \n",
       "9  -0.008426  0.000484  1.000000  ... -0.011932 -0.051510 -0.035967 -0.010876   \n",
       "10 -0.002419  0.110689  0.003689  ... -0.025739 -0.023225 -0.001835 -0.001643   \n",
       "11 -0.072075  0.006904  0.115718  ... -0.401001  0.623796  0.602679 -0.254972   \n",
       "12 -0.001048  0.035103  0.002148  ... -0.010879 -0.010427 -0.005284  0.003412   \n",
       "13 -0.003310  0.086343  0.014401  ... -0.028856 -0.006773  0.006045 -0.004578   \n",
       "14 -0.002225  0.111474  0.000279  ... -0.012667 -0.021692 -0.016670  0.004411   \n",
       "15 -0.001109  0.034281  0.001704  ... -0.011406 -0.011184 -0.006177  0.003798   \n",
       "16 -0.002334  0.030251  0.022945  ... -0.001672 -0.019635 -0.017488  0.007586   \n",
       "17 -0.001689 -0.000146  0.001953  ... -0.009394 -0.012706 -0.006478 -0.003328   \n",
       "18 -0.003600  0.012917 -0.003054  ... -0.005513  0.003124  0.005680  0.001756   \n",
       "19 -0.008595 -0.000745  0.864388  ... -0.013131 -0.065675 -0.054148 -0.005913   \n",
       "20 -0.020873 -0.005603 -0.068376  ...  0.467910 -0.394411 -0.472053  0.164268   \n",
       "21  0.024031 -0.002846 -0.034457  ...  0.150257  0.203454  0.182723 -0.106912   \n",
       "22 -0.043258 -0.004914 -0.058604  ...  0.395352 -0.558051 -0.623194 -0.018171   \n",
       "23 -0.056250 -0.004874 -0.058234  ...  0.393074 -0.555215 -0.619476 -0.028914   \n",
       "24 -0.032861 -0.002886 -0.031998  ...  0.070790 -0.253365 -0.260014  0.377480   \n",
       "25 -0.033315 -0.002887 -0.031186  ...  0.073516 -0.251837 -0.258024  0.381989   \n",
       "26  0.054629  0.005947  0.069378  ... -0.509290  0.704974  0.788334 -0.164309   \n",
       "27 -0.026492 -0.002696 -0.017843  ...  0.192422 -0.299466 -0.330184  0.493908   \n",
       "28 -0.026047 -0.002892 -0.026043  ... -0.360080  0.152886  0.291126 -0.118603   \n",
       "29  0.040414 -0.005726 -0.011932  ...  1.000000 -0.302581 -0.517897  0.142474   \n",
       "30 -0.045733 -0.007911 -0.051510  ... -0.302581  1.000000  0.896385 -0.390399   \n",
       "31 -0.049032 -0.005887 -0.035967  ... -0.517897  0.896385  1.000000 -0.418948   \n",
       "32  0.056631  0.005119 -0.010876  ...  0.142474 -0.390399 -0.418948  1.000000   \n",
       "33  0.036108  0.000670 -0.034460  ... -0.313460 -0.068358  0.137008  0.232357   \n",
       "34 -0.016115  0.001927 -0.024248  ... -0.455401 -0.004198  0.197968  0.019440   \n",
       "35 -0.051692 -0.004699 -0.058061  ...  0.411132 -0.572867 -0.639659 -0.017730   \n",
       "36 -0.055601 -0.004818 -0.057932  ...  0.407421 -0.567730 -0.632340 -0.026522   \n",
       "37  0.028394 -0.002987 -0.029851  ...  0.073694 -0.252624 -0.259517  0.410382   \n",
       "38 -0.033472 -0.002900 -0.031210  ...  0.069753 -0.255114 -0.260559  0.386967   \n",
       "\n",
       "          33        34        35        36        37        38  \n",
       "0   0.227889 -0.026399 -0.064810 -0.063982  0.174528  0.198709  \n",
       "1   0.569278  0.364310 -0.278256 -0.277162 -0.136476 -0.166853  \n",
       "2  -0.086222 -0.054611  0.404127  0.409593  0.101639  0.109540  \n",
       "3  -0.042851 -0.070647  0.273909  0.280337  0.601219  0.644820  \n",
       "4   0.002045 -0.001513 -0.004560 -0.002192 -0.001919  0.007065  \n",
       "5   0.013042 -0.001409 -0.003300 -0.003214  0.013181  0.012611  \n",
       "6   0.034695  0.070904  0.020422  0.013013 -0.005435 -0.005554  \n",
       "7   0.036108 -0.016115 -0.051692 -0.055601  0.028394 -0.033472  \n",
       "8   0.000670  0.001927 -0.004699 -0.004818 -0.002987 -0.002900  \n",
       "9  -0.034460 -0.024248 -0.058061 -0.057932 -0.029851 -0.031210  \n",
       "10 -0.005353  0.005655 -0.012071 -0.012664  0.018440  0.016957  \n",
       "11 -0.162210 -0.056095 -0.491137 -0.492686 -0.275336 -0.272967  \n",
       "12 -0.002255  0.004384 -0.004380 -0.004725 -0.003639 -0.003345  \n",
       "13  0.000807  0.013386 -0.017768 -0.015371 -0.008906 -0.009580  \n",
       "14 -0.006150  0.009164 -0.006697 -0.004160 -0.004294 -0.005431  \n",
       "15 -0.001934  0.004699 -0.004753 -0.005059 -0.003817 -0.003607  \n",
       "16 -0.006350  0.002943  0.002685 -0.000822 -0.004675 -0.004720  \n",
       "17  0.014769 -0.001770 -0.011376 -0.010052 -0.005068 -0.006854  \n",
       "18 -0.012659  0.001408 -0.017940 -0.019583 -0.012568 -0.012746  \n",
       "19 -0.035255 -0.024220 -0.059927 -0.059841 -0.029849 -0.032491  \n",
       "20 -0.136143 -0.205615  0.458189  0.459821  0.177824  0.167923  \n",
       "21  0.161665 -0.059236 -0.146457 -0.145625 -0.101942 -0.112881  \n",
       "22 -0.276532 -0.172628  0.979045  0.981034 -0.231577 -0.226486  \n",
       "23 -0.275519 -0.170816  0.977497  0.986002 -0.235098 -0.232924  \n",
       "24  0.032614  0.034242 -0.225986 -0.224985  0.927218  0.964776  \n",
       "25  0.029745  0.031230 -0.226210 -0.230309  0.918888  0.970648  \n",
       "26  0.280751  0.216147 -0.760993 -0.765407 -0.215915 -0.214932  \n",
       "27 -0.010509 -0.086014  0.051301  0.047245  0.225405  0.277130  \n",
       "28  0.249142  0.379751 -0.226277 -0.226698 -0.078592 -0.083413  \n",
       "29 -0.313460 -0.455401  0.411132  0.407421  0.073694  0.069753  \n",
       "30 -0.068358 -0.004198 -0.572867 -0.567730 -0.252624 -0.255114  \n",
       "31  0.137008  0.197968 -0.639659 -0.632340 -0.259517 -0.260559  \n",
       "32  0.232357  0.019440 -0.017730 -0.026522  0.410382  0.386967  \n",
       "33  1.000000  0.404123 -0.279398 -0.277056  0.037307  0.028106  \n",
       "34  0.404123  1.000000 -0.174468 -0.173138  0.039741  0.040182  \n",
       "35 -0.279398 -0.174468  1.000000  0.985073 -0.235077 -0.227578  \n",
       "36 -0.277056 -0.173138  0.985073  1.000000 -0.234381 -0.232396  \n",
       "37  0.037307  0.039741 -0.235077 -0.234381  1.000000  0.925828  \n",
       "38  0.028106  0.040182 -0.227578 -0.232396  0.925828  1.000000  \n",
       "\n",
       "[39 rows x 39 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cons_filter = pd.DataFrame(X_train_cons_filter)\n",
    "corrmat = X_train_cons_filter.corr()\n",
    "corr_features = get_correlation(X_train_cons_filter, 0.90)\n",
    "print(corr_features)\n",
    "corrmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0     1.000000\n",
       "    1     0.009967\n",
       "    2     0.002528\n",
       "    3     0.176394\n",
       "    4     0.054169\n",
       "            ...   \n",
       "38  34    0.040182\n",
       "    35    0.227578\n",
       "    36    0.232396\n",
       "    37    0.925828\n",
       "    38    1.000000\n",
       "Length: 1521, dtype: float64"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data = corrmat.abs().stack()\n",
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38  38    1.000000\n",
       "18  18    1.000000\n",
       "21  21    1.000000\n",
       "22  22    1.000000\n",
       "23  23    1.000000\n",
       "            ...   \n",
       "4   8     0.000065\n",
       "16  5     0.000045\n",
       "5   16    0.000045\n",
       "4   5     0.000001\n",
       "5   4     0.000001\n",
       "Length: 1521, dtype: float64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data = corr_data.sort_values(ascending=False)\n",
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12  15    0.998950\n",
       "15  12    0.998950\n",
       "22  23    0.993558\n",
       "23  22    0.993558\n",
       "25  24    0.989219\n",
       "24  25    0.989219\n",
       "36  23    0.986002\n",
       "23  36    0.986002\n",
       "36  35    0.985073\n",
       "35  36    0.985073\n",
       "22  36    0.981034\n",
       "36  22    0.981034\n",
       "35  22    0.979045\n",
       "22  35    0.979045\n",
       "23  35    0.977497\n",
       "35  23    0.977497\n",
       "25  38    0.970648\n",
       "38  25    0.970648\n",
       "24  38    0.964776\n",
       "38  24    0.964776\n",
       "37  24    0.927218\n",
       "24  37    0.927218\n",
       "37  38    0.925828\n",
       "38  37    0.925828\n",
       "25  37    0.918888\n",
       "37  25    0.918888\n",
       "dtype: float64"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data = corr_data[corr_data>0.90]\n",
    "corr_data = corr_data[corr_data<1]\n",
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>corr_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.998950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0.998950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0.993558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>0.993558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.989219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>0.989219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>0.986002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>0.986002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>0.985073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>0.985073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>0.981034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>0.981034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>0.979045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>0.979045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>0.977497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.977497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>0.970648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>0.970648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>0.964776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>0.964776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>0.927218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>0.927218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>0.925828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>0.925828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>0.918888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>0.918888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature1  Feature2  corr_value\n",
       "0         12        15    0.998950\n",
       "1         15        12    0.998950\n",
       "2         22        23    0.993558\n",
       "3         23        22    0.993558\n",
       "4         25        24    0.989219\n",
       "5         24        25    0.989219\n",
       "6         36        23    0.986002\n",
       "7         23        36    0.986002\n",
       "8         36        35    0.985073\n",
       "9         35        36    0.985073\n",
       "10        22        36    0.981034\n",
       "11        36        22    0.981034\n",
       "12        35        22    0.979045\n",
       "13        22        35    0.979045\n",
       "14        23        35    0.977497\n",
       "15        35        23    0.977497\n",
       "16        25        38    0.970648\n",
       "17        38        25    0.970648\n",
       "18        24        38    0.964776\n",
       "19        38        24    0.964776\n",
       "20        37        24    0.927218\n",
       "21        24        37    0.927218\n",
       "22        37        38    0.925828\n",
       "23        38        37    0.925828\n",
       "24        25        37    0.918888\n",
       "25        37        25    0.918888"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data = pd.DataFrame(corr_data).reset_index()\n",
    "corr_data.columns = ['Feature1', 'Feature2', 'corr_value']\n",
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_feature_list = []\n",
    "correlated_groups_list = []\n",
    "for feature in corr_data.Feature1.unique():\n",
    "    if feature not in grouped_feature_list:\n",
    "        correlated_block = corr_data[corr_data.Feature1==feature]\n",
    "        grouped_feature_list = grouped_feature_list + list(correlated_block.Feature2.unique())+[feature]\n",
    "        correlated_groups_list.append(correlated_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correlated_groups_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   Feature1  Feature2  corr_value\n",
       " 0        12        15     0.99895,     Feature1  Feature2  corr_value\n",
       " 2         22        23    0.993558\n",
       " 10        22        36    0.981034\n",
       " 13        22        35    0.979045,     Feature1  Feature2  corr_value\n",
       " 4         25        24    0.989219\n",
       " 16        25        38    0.970648\n",
       " 24        25        37    0.918888]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlated_groups_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2  corr_value\n",
      "0        12        15     0.99895\n",
      "\n",
      "    Feature1  Feature2  corr_value\n",
      "2         22        23    0.993558\n",
      "10        22        36    0.981034\n",
      "13        22        35    0.979045\n",
      "\n",
      "    Feature1  Feature2  corr_value\n",
      "4         25        24    0.989219\n",
      "16        25        38    0.970648\n",
      "24        25        37    0.918888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group in correlated_groups_list:\n",
    "    print(group)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feature = []\n",
    "for group in correlated_groups_list:\n",
    "    features = list(group.Feature1.unique())+ list(group.Feature2.unique())\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    rf.fit(X_train_cons_filter[features], y_train)\n",
    "    \n",
    "    importance = pd.concat([pd.Series(features), pd.Series(rf.feature_importances_)], axis = 1)\n",
    "    importance.columns = ['features', 'importance']\n",
    "    importance.sort_values(by ='importance', ascending = False, inplace = True)\n",
    "    feat = importance.iloc[0]\n",
    "    important_feature.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[features      12.000000\n",
       " importance     0.678742\n",
       " Name: 0, dtype: float64, features      35.000000\n",
       " importance     0.473006\n",
       " Name: 3, dtype: float64, features      37.000000\n",
       " importance     0.408372\n",
       " Name: 3, dtype: float64]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.678742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.473006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.408372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features  importance\n",
       "0      12.0    0.678742\n",
       "1      35.0    0.473006\n",
       "2      37.0    0.408372"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_feature = pd.DataFrame(important_feature)\n",
    "important_feature.reset_index(inplace = True, drop = True)\n",
    "important_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 38, 15, 23, 25]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_consider = set(important_feature['features'])\n",
    "features_to_remove = set(corr_features) -set(features_to_consider)\n",
    "features_to_remove = list(features_to_remove)\n",
    "features_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100777, 34)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_grouped_uncorr = X_train_cons_filter.drop(labels=features_to_remove, axis = 1)\n",
    "X_train_grouped_uncorr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25195, 34)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_cons_filter = pd.DataFrame(x_test_cons_filter)\n",
    "X_test_grouped_uncorr = x_test_cons_filter.drop(labels=features_to_remove, axis =1)\n",
    "X_test_grouped_uncorr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9989283588013494\n",
      "CPU times: user 15.8 s, sys: 288 ms, total: 16.1 s\n",
      "Wall time: 4.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "run_randomForest(X_train_grouped_uncorr, X_test_grouped_uncorr, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DecisionTreeClassifier(X_train, X_test, y_train, y_test):\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgboost(X_train, X_test, y_train, y_test):\n",
    "    model = xgb.XGBClassifier(n_estimators=100, objective='multi:softprob', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm(X_train, X_test, y_train, y_test):\n",
    "    model = svm.SVC(decision_function_shape='ovo')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9981345505060528\n",
      "CPU times: user 692 ms, sys: 0 ns, total: 692 ms\n",
      "Wall time: 692 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "run_DecisionTreeClassifier(X_train_grouped_uncorr, X_test_grouped_uncorr, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9975788846993451\n",
      "CPU times: user 40.1 s, sys: 0 ns, total: 40.1 s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_xgboost(X_train_grouped_uncorr, X_test_grouped_uncorr, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_svm(X_train_grouped_uncorr, X_test_grouped_uncorr, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
