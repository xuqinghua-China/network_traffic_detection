{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "209kwqP_BgSg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gydvagNFBmFQ",
    "outputId": "36de43f1-1372-41d0-8de5-bd9a7bea72dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the data sets\n",
    "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/bytes-to-text.csv', names=['raw-bytes', 'tag'], header=None)\n",
    "print('Data Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "nPYJnlKkOmZI",
    "outputId": "1181527d-9b34-4a89-a09a-6b99b2be827b"
   },
   "outputs": [],
   "source": [
    "# remove those rows which are larger than 50000 word size\n",
    "df['length'] = df['raw-bytes'].str.len()\n",
    "lengths = df['length']\n",
    "todel = lengths[lengths>50000]\n",
    "df = df.drop(todel.index)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "YKS3DhiXP_0o",
    "outputId": "a0a1ff1d-b138-4691-d8d1-45093802a80e"
   },
   "outputs": [],
   "source": [
    "data = df['raw-bytes'].to_numpy()\n",
    "\n",
    "all_text = ' '.join(data)\n",
    "all_words = all_text.split()\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(all_words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "print('vocab length: ', len(vocab))\n",
    "\n",
    "vocab_to_int = {word:i for i, word in enumerate(vocab[:10000], 1)}\n",
    "\n",
    "pickle.dump(vocab_to_int, open('/content/drive/My Drive/Colab Notebooks/datasets/vocab_to_int.p', \"wb\"))\n",
    "\n",
    "print('Vocab to Int save to drive')\n",
    "\n",
    "limit_bytes_as_vocab = []\n",
    "for raw in data:\n",
    "    limit_bytes_as_vocab.append([word if word in vocab_to_int else 'unkown' for word in raw.split()])\n",
    "print('Process Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPRfYO4ix49C"
   },
   "outputs": [],
   "source": [
    "for i, line in enumerate(limit_bytes_as_vocab):\n",
    "  text_list = line\n",
    "  if len(text_list)<1200:\n",
    "    text_list.extend(['0']*(1200-len(text_list)))\n",
    "  limit_bytes_as_vocab[i] = text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KsQZ_UytuCVC",
    "outputId": "5876d0b3-49f6-4203-8866-624e52d50f1d"
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=1,\n",
    "                     window=3,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     sg=1,\n",
    "                     compute_loss=True,\n",
    "                     workers=2)\n",
    "\n",
    "t = time()\n",
    "w2v_model.build_vocab(limit_bytes_as_vocab, progress_per=1000)\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "tgSpLMbZuCYG",
    "outputId": "9438ddb1-177c-4cdc-bffe-0557e1a42429"
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(limit_bytes_as_vocab, total_examples=w2v_model.corpus_count, epochs=20, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "w2v_model.save('/content/drive/My Drive/Colab Notebooks/datasets/train-word2vec-model.model')\n",
    "print('Model is Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8f5f9gzTuCSX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJ1wOuA2hn6n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aCqQnDjhnyM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "56RY0oFFQIyX",
    "outputId": "8ec44a7d-7975-43c2-c682-7cbdcfeccf6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of train data:  24244\n",
      "Len of test data:  2520\n",
      "train_y:  (24243, 1)\n",
      "test_y:  (2520, 1)\n"
     ]
    }
   ],
   "source": [
    "# targets = df['target']\n",
    "targets = targets.reshape(-1, 1)\n",
    "\n",
    "test_index=[]\n",
    "normal=np.random.choice(range(16117, 26763), 1000)\n",
    "test_index.extend(set(normal))\n",
    "\n",
    "Inflit=np.random.choice(range(6702, 16116), 900)\n",
    "test_index.extend(set(Inflit))\n",
    "\n",
    "http=np.random.choice(range(3594, 6701), 400)\n",
    "test_index.extend(set(http))\n",
    "\n",
    "bfssh=np.random.choice(range(0, 3593), 350)\n",
    "test_index.extend(set(bfssh))\n",
    "\n",
    "len(test_index)\n",
    "\n",
    "train_x = []\n",
    "test_x = []\n",
    "\n",
    "for i in range(26764):\n",
    "  if i in test_index:\n",
    "    test_x.append(text_data[i])\n",
    "  else:\n",
    "    train_x.append(text_data[i])\n",
    "\n",
    "\n",
    "train_y = targets[list(set(range(0, 26763)).symmetric_difference(set(test_index))), :]\n",
    "test_y = targets[test_index, :]\n",
    "# print('test_x: ', test_x.shape)\n",
    "# print('train_x: ', train_x.shape)\n",
    "print('Len of train data: ', len(train_x))\n",
    "print('Len of test data: ', len(test_x))\n",
    "print('train_y: ', train_y.shape)\n",
    "print('test_y: ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PE9xqdnZlLSd"
   },
   "outputs": [],
   "source": [
    "# test_x"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Using Word2Vec Embedding-vocab1000-Feature1000.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
